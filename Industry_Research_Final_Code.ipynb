{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl+f6u0bnE10LzC/r9QPnu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruwanwija/Research-Models/blob/main/Industry_Research_Final_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from sklearn import svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Preprocess the text\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "        return ' '.join(tokens)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Sample dataset II.csv')\n",
        "\n",
        "# Preprocess the text data\n",
        "df['preprocessed_text'] = df['reviews.text'].apply(preprocess_text)\n",
        "\n",
        "# Define label mapping\n",
        "labels = [\"Location\", \"Food Quality\", \"Value for Money\", \"Comfort\", \"Staff Behavior\"]\n",
        "\n",
        "# Create an instance of MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "# Apply K-means clustering to generate labels (dummy labels for demonstration)\n",
        "num_clusters = len(labels)  # Assuming we have 6 labels as defined above\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['preprocessed_text'])\n",
        "\n",
        "# Fit KMeans model\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "df['cluster_label'] = kmeans.labels_\n",
        "\n",
        "# Create a binary indicator for each cluster (multi-label format)\n",
        "y = pd.get_dummies(df['cluster_label']).values\n",
        "\n",
        "# Use StratifiedKFold to ensure stratified sampling\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Store accuracies, F1 scores, and probabilities for each fold\n",
        "accuracies = []\n",
        "f1_scores = []\n",
        "mean_probabilities = np.zeros(num_clusters)  # To store mean probabilities for each class\n",
        "\n",
        "for train_index, test_index in stratified_kfold.split(X, np.argmax(y, axis=1)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Create the SVM model\n",
        "    base_model = svm.SVC(kernel='linear', probability=True)\n",
        "\n",
        "    # Wrap the SVC model with OneVsRestClassifier to handle multi-label classification\n",
        "    model = OneVsRestClassifier(base_model)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # New record to predict\n",
        "    new_record = [\"Great place with unique room structure with wooden top. It helped spending our own time without any disturbance. We can see Beautiful Sun rise from the room by opening the curtain.\"]\n",
        "    new_record_preprocessed = [preprocess_text(text) for text in new_record]\n",
        "    new_record_tfidf = vectorizer.transform(new_record_preprocessed)\n",
        "\n",
        "    # Predict the label for the new record\n",
        "    predicted_labels_numeric = model.predict(new_record_tfidf)\n",
        "\n",
        "    # Get the probabilities for each label category\n",
        "    probabilities = model.predict_proba(new_record_tfidf)\n",
        "\n",
        "    # Update mean probabilities\n",
        "    mean_probabilities += probabilities[0]  # Sum up probabilities for averaging later\n",
        "\n",
        "    # Display the predicted labels and probabilities\n",
        "    probability_dict = {labels[i]: probabilities[0][i] for i in range(num_clusters)}\n",
        "\n",
        "    # Find the label with the highest probability\n",
        "    highest_label = max(probability_dict, key=probability_dict.get)\n",
        "    highest_probability = probability_dict[highest_label]\n",
        "\n",
        "    # Display results for the current fold\n",
        "    print(f\"Predicted Labels: {predicted_labels_numeric}\")\n",
        "    print(\"Probabilities for each class:\")\n",
        "    for label, prob in probability_dict.items():\n",
        "        print(f\"{label}: {prob:.4f}\")  # Format to 4 decimal places\n",
        "\n",
        "    print(f\"\\nHighest Probability Label: {highest_label} with probability: {highest_probability:.4f}\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy and F1 score using binary arrays\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "    # Store scores for the current fold\n",
        "    accuracies.append(accuracy)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate mean probabilities\n",
        "mean_probabilities /= stratified_kfold.get_n_splits()  # Average the probabilities over folds\n",
        "\n",
        "# Find the highest mean probability\n",
        "highest_mean_label = labels[np.argmax(mean_probabilities)]\n",
        "highest_mean_probability = np.max(mean_probabilities)\n",
        "\n",
        "# Display overall results\n",
        "print(f'\\nMean Accuracy: {np.mean(accuracies)}')\n",
        "print(f'Mean F1 Score: {np.mean(f1_scores)}')\n",
        "print(\"\\nMean Probabilities for each class:\")\n",
        "for label, mean_prob in zip(labels, mean_probabilities):\n",
        "    print(f\"{label}: {mean_prob:.4f}\")\n",
        "\n",
        "print(f\"\\nHighest Mean Probability Label: {highest_mean_label} with probability: {highest_mean_probability:.4f}\")"
      ],
      "metadata": {
        "id": "lDUPtkgh4Aot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262d2cb5-fa5a-459e-d859-2a0ed46675a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0031\n",
            "Food Quality: 0.4373\n",
            "Value for Money: 0.0008\n",
            "Comfort: 0.0005\n",
            "Staff Behavior: 0.5979\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.5979\n",
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0025\n",
            "Food Quality: 0.2283\n",
            "Value for Money: 0.0008\n",
            "Comfort: 0.0004\n",
            "Staff Behavior: 0.8911\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.8911\n",
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0025\n",
            "Food Quality: 0.1475\n",
            "Value for Money: 0.0005\n",
            "Comfort: 0.0003\n",
            "Staff Behavior: 0.8975\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.8975\n",
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0028\n",
            "Food Quality: 0.1395\n",
            "Value for Money: 0.0024\n",
            "Comfort: 0.0003\n",
            "Staff Behavior: 0.9121\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.9121\n",
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0025\n",
            "Food Quality: 0.2067\n",
            "Value for Money: 0.0011\n",
            "Comfort: 0.0002\n",
            "Staff Behavior: 0.9850\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.9850\n",
            "\n",
            "Mean Accuracy: 0.7947738693467337\n",
            "Mean F1 Score: 0.8710777307552418\n",
            "\n",
            "Mean Probabilities for each class:\n",
            "Location: 0.0027\n",
            "Food Quality: 0.2319\n",
            "Value for Money: 0.0011\n",
            "Comfort: 0.0003\n",
            "Staff Behavior: 0.8567\n",
            "\n",
            "Highest Mean Probability Label: Staff Behavior with probability: 0.8567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming `model` is your trained SVM model\n",
        "with open('svm_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n"
      ],
      "metadata": {
        "id": "CkfooGByXTnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming `model` is your trained SVM model and `vectorizer` is the TF-IDF vectorizer\n",
        "with open('svm_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n",
        "\n",
        "with open('vectorizer.pkl', 'wb') as vec_file:\n",
        "    pickle.dump(vectorizer, vec_file)\n"
      ],
      "metadata": {
        "id": "rrpXS8RX--3O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM"
      ],
      "metadata": {
        "id": "2Rvbs3Ftbe2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from sklearn import svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, f1_score, multilabel_confusion_matrix, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Preprocess the text\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "        return ' '.join(tokens)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Sample dataset II.csv')\n",
        "\n",
        "# Preprocess the text data\n",
        "df['preprocessed_text'] = df['reviews.text'].apply(preprocess_text)\n",
        "\n",
        "# Define label mapping\n",
        "labels = [\"Location\", \"Food Quality\", \"Value for Money\", \"Comfort\", \"Staff Behavior\"]\n",
        "\n",
        "# Create an instance of MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "# Apply K-means clustering to generate labels (dummy labels for demonstration)\n",
        "num_clusters = len(labels)  # Assuming we have 6 labels as defined above\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['preprocessed_text'])\n",
        "\n",
        "# Fit KMeans model\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "df['cluster_label'] = kmeans.labels_\n",
        "\n",
        "# Create a binary indicator for each cluster (multi-label format)\n",
        "y = pd.get_dummies(df['cluster_label']).values\n",
        "\n",
        "# Use StratifiedKFold to ensure stratified sampling\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Store accuracies, F1 scores, and probabilities for each fold\n",
        "accuracies = []\n",
        "f1_scores = []\n",
        "mean_probabilities = np.zeros(num_clusters)  # To store mean probabilities for each class\n",
        "\n",
        "for train_index, test_index in stratified_kfold.split(X, np.argmax(y, axis=1)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Create the SVM model\n",
        "    base_model = svm.SVC(kernel='linear', probability=True)\n",
        "\n",
        "    # Wrap the SVC model with OneVsRestClassifier to handle multi-label classification\n",
        "    model = OneVsRestClassifier(base_model)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # New record to predict\n",
        "    new_record = [\"Great place with unique room structure with wooden top. It helped spending our own time without any disturbance. We can see Beautiful Sun rise from the room by opening the curtain.\"]\n",
        "    new_record_preprocessed = [preprocess_text(text) for text in new_record]\n",
        "    new_record_tfidf = vectorizer.transform(new_record_preprocessed)\n",
        "\n",
        "    # Predict the label for the new record\n",
        "    predicted_labels_numeric = model.predict(new_record_tfidf)\n",
        "\n",
        "    # Get the probabilities for each label category\n",
        "    probabilities = model.predict_proba(new_record_tfidf)\n",
        "\n",
        "    # Update mean probabilities\n",
        "    mean_probabilities += probabilities[0]  # Sum up probabilities for averaging later\n",
        "\n",
        "    # Display the predicted labels and probabilities\n",
        "    probability_dict = {labels[i]: probabilities[0][i] for i in range(num_clusters)}\n",
        "\n",
        "    # Find the label with the highest probability\n",
        "    highest_label = max(probability_dict, key=probability_dict.get)\n",
        "    highest_probability = probability_dict[highest_label]\n",
        "\n",
        "    # Display results for the current fold\n",
        "    print(f\"Predicted Labels: {predicted_labels_numeric}\")\n",
        "    print(\"Probabilities for each class:\")\n",
        "    for label, prob in probability_dict.items():\n",
        "        print(f\"{label}: {prob:.4f}\")  # Format to 4 decimal places\n",
        "\n",
        "    print(f\"\\nHighest Probability Label: {highest_label} with probability: {highest_probability:.4f}\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate the confusion matrix for each label\n",
        "    conf_matrix = multilabel_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Display confusion matrices for each label\n",
        "    for i, label in enumerate(labels):\n",
        "        print(f\"\\nConfusion Matrix for {label}:\")\n",
        "        print(conf_matrix[i])\n",
        "\n",
        "    # Generate and print precision, recall, and F1 score for each label\n",
        "    print(f\"\\nClassification Report for Fold:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=labels))\n",
        "\n",
        "    # Calculate accuracy and F1 score using binary arrays\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "    # Store scores for the current fold\n",
        "    accuracies.append(accuracy)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate mean probabilities\n",
        "mean_probabilities /= stratified_kfold.get_n_splits()  # Average the probabilities over folds\n",
        "\n",
        "# Find the highest mean probability\n",
        "highest_mean_label = labels[np.argmax(mean_probabilities)]\n",
        "highest_mean_probability = np.max(mean_probabilities)\n",
        "\n",
        "# Display overall results\n",
        "print(f'\\nMean Accuracy: {np.mean(accuracies)}')\n",
        "print(f'Mean F1 Score: {np.mean(f1_scores)}')\n",
        "print(\"\\nMean Probabilities for each class:\")\n",
        "for label, mean_prob in zip(labels, mean_probabilities):\n",
        "    print(f\"{label}: {mean_prob:.4f}\")\n",
        "\n",
        "print(f\"\\nHighest Mean Probability Label: {highest_mean_label} with probability: {highest_mean_probability:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evaqiIKqcLEb",
        "outputId": "5c28d6fc-3bc3-4bba-b5d8-fbc675bcb9c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0033\n",
            "Food Quality: 0.4074\n",
            "Value for Money: 0.0007\n",
            "Comfort: 0.0005\n",
            "Staff Behavior: 0.5647\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.5647\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  0  13]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[143   7]\n",
            " [ 14  36]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[182   0]\n",
            " [  3  15]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[175   0]\n",
            " [ 10  15]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[99  7]\n",
            " [ 5 89]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      1.00      1.00        13\n",
            "   Food Quality       0.84      0.72      0.77        50\n",
            "Value for Money       1.00      0.83      0.91        18\n",
            "        Comfort       1.00      0.60      0.75        25\n",
            " Staff Behavior       0.93      0.95      0.94        94\n",
            "\n",
            "      micro avg       0.92      0.84      0.88       200\n",
            "      macro avg       0.95      0.82      0.87       200\n",
            "   weighted avg       0.93      0.84      0.87       200\n",
            "    samples avg       0.82      0.84      0.83       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0024\n",
            "Food Quality: 0.1922\n",
            "Value for Money: 0.0028\n",
            "Comfort: 0.0005\n",
            "Staff Behavior: 0.8928\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.8928\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  1  12]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[145   5]\n",
            " [ 11  39]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[182   0]\n",
            " [  8  10]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[171   4]\n",
            " [  9  16]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[98  8]\n",
            " [ 5 89]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      0.92      0.96        13\n",
            "   Food Quality       0.89      0.78      0.83        50\n",
            "Value for Money       1.00      0.56      0.71        18\n",
            "        Comfort       0.80      0.64      0.71        25\n",
            " Staff Behavior       0.92      0.95      0.93        94\n",
            "\n",
            "      micro avg       0.91      0.83      0.87       200\n",
            "      macro avg       0.92      0.77      0.83       200\n",
            "   weighted avg       0.91      0.83      0.86       200\n",
            "    samples avg       0.81      0.83      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0025\n",
            "Food Quality: 0.1814\n",
            "Value for Money: 0.0007\n",
            "Comfort: 0.0002\n",
            "Staff Behavior: 0.9073\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.9073\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  0  13]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[147   3]\n",
            " [ 13  37]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[181   1]\n",
            " [  6  12]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[174   1]\n",
            " [  9  16]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[97  9]\n",
            " [ 4 90]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      1.00      1.00        13\n",
            "   Food Quality       0.93      0.74      0.82        50\n",
            "Value for Money       0.92      0.67      0.77        18\n",
            "        Comfort       0.94      0.64      0.76        25\n",
            " Staff Behavior       0.91      0.96      0.93        94\n",
            "\n",
            "      micro avg       0.92      0.84      0.88       200\n",
            "      macro avg       0.94      0.80      0.86       200\n",
            "   weighted avg       0.92      0.84      0.87       200\n",
            "    samples avg       0.82      0.84      0.83       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0029\n",
            "Food Quality: 0.1466\n",
            "Value for Money: 0.0033\n",
            "Comfort: 0.0001\n",
            "Staff Behavior: 0.8999\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.8999\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  0  13]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[146   4]\n",
            " [ 11  39]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[182   0]\n",
            " [ 10   8]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[175   0]\n",
            " [  7  18]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[98  8]\n",
            " [ 7 87]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      1.00      1.00        13\n",
            "   Food Quality       0.91      0.78      0.84        50\n",
            "Value for Money       1.00      0.44      0.62        18\n",
            "        Comfort       1.00      0.72      0.84        25\n",
            " Staff Behavior       0.92      0.93      0.92        94\n",
            "\n",
            "      micro avg       0.93      0.82      0.88       200\n",
            "      macro avg       0.96      0.77      0.84       200\n",
            "   weighted avg       0.94      0.82      0.87       200\n",
            "    samples avg       0.81      0.82      0.82       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0025\n",
            "Food Quality: 0.2253\n",
            "Value for Money: 0.0003\n",
            "Comfort: 0.0002\n",
            "Staff Behavior: 0.9818\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.9818\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  2  10]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[146   3]\n",
            " [ 12  38]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[180   0]\n",
            " [  6  13]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[172   2]\n",
            " [ 12  13]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[98  8]\n",
            " [ 9 84]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      0.83      0.91        12\n",
            "   Food Quality       0.93      0.76      0.84        50\n",
            "Value for Money       1.00      0.68      0.81        19\n",
            "        Comfort       0.87      0.52      0.65        25\n",
            " Staff Behavior       0.91      0.90      0.91        93\n",
            "\n",
            "      micro avg       0.92      0.79      0.85       199\n",
            "      macro avg       0.94      0.74      0.82       199\n",
            "   weighted avg       0.92      0.79      0.85       199\n",
            "    samples avg       0.78      0.79      0.79       199\n",
            "\n",
            "\n",
            "Mean Accuracy: 0.7947738693467337\n",
            "Mean F1 Score: 0.8710777307552418\n",
            "\n",
            "Mean Probabilities for each class:\n",
            "Location: 0.0027\n",
            "Food Quality: 0.2306\n",
            "Value for Money: 0.0016\n",
            "Comfort: 0.0003\n",
            "Staff Behavior: 0.8493\n",
            "\n",
            "Highest Mean Probability Label: Staff Behavior with probability: 0.8493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "IsKxO7sTckv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, f1_score, multilabel_confusion_matrix, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Preprocess the text\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "        return ' '.join(tokens)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Sample dataset II.csv')\n",
        "\n",
        "# Preprocess the text data\n",
        "df['preprocessed_text'] = df['reviews.text'].apply(preprocess_text)\n",
        "\n",
        "# Define label mapping\n",
        "labels = [\"Location\", \"Food Quality\", \"Value for Money\", \"Comfort\", \"Staff Behavior\"]\n",
        "\n",
        "# Create an instance of MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "# Apply K-means clustering to generate labels (dummy labels for demonstration)\n",
        "num_clusters = len(labels)  # Assuming we have 6 labels as defined above\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['preprocessed_text'])\n",
        "\n",
        "# Fit KMeans model\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "df['cluster_label'] = kmeans.labels_\n",
        "\n",
        "# Create a binary indicator for each cluster (multi-label format)\n",
        "y = pd.get_dummies(df['cluster_label']).values\n",
        "\n",
        "# Use StratifiedKFold to ensure stratified sampling\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Store accuracies, F1 scores, and probabilities for each fold\n",
        "accuracies = []\n",
        "f1_scores = []\n",
        "mean_probabilities = np.zeros(num_clusters)  # To store mean probabilities for each class\n",
        "\n",
        "for train_index, test_index in stratified_kfold.split(X, np.argmax(y, axis=1)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Create the Logistic Regression model\n",
        "    base_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "    # Wrap the Logistic Regression model with OneVsRestClassifier to handle multi-label classification\n",
        "    model = OneVsRestClassifier(base_model)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # New record to predict\n",
        "    new_record = [\"Great place with unique room structure with wooden top. It helped spending our own time without any disturbance. We can see Beautiful Sun rise from the room by opening the curtain.\"]\n",
        "    new_record_preprocessed = [preprocess_text(text) for text in new_record]\n",
        "    new_record_tfidf = vectorizer.transform(new_record_preprocessed)\n",
        "\n",
        "    # Predict the label for the new record\n",
        "    predicted_labels_numeric = model.predict(new_record_tfidf)\n",
        "\n",
        "    # Get the probabilities for each label category\n",
        "    probabilities = model.predict_proba(new_record_tfidf)\n",
        "\n",
        "    # Update mean probabilities\n",
        "    mean_probabilities += probabilities[0]  # Sum up probabilities for averaging later\n",
        "\n",
        "    # Display the predicted labels and probabilities\n",
        "    probability_dict = {labels[i]: probabilities[0][i] for i in range(num_clusters)}\n",
        "\n",
        "    # Find the label with the highest probability\n",
        "    highest_label = max(probability_dict, key=probability_dict.get)\n",
        "    highest_probability = probability_dict[highest_label]\n",
        "\n",
        "    # Display results for the current fold\n",
        "    print(f\"Predicted Labels: {predicted_labels_numeric}\")\n",
        "    print(\"Probabilities for each class:\")\n",
        "    for label, prob in probability_dict.items():\n",
        "        print(f\"{label}: {prob:.4f}\")  # Format to 4 decimal places\n",
        "\n",
        "    print(f\"\\nHighest Probability Label: {highest_label} with probability: {highest_probability:.4f}\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate the confusion matrix for each label\n",
        "    conf_matrix = multilabel_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Display confusion matrices for each label\n",
        "    for i, label in enumerate(labels):\n",
        "        print(f\"\\nConfusion Matrix for {label}:\")\n",
        "        print(conf_matrix[i])\n",
        "\n",
        "    # Generate and print precision, recall, and F1 score for each label\n",
        "    print(f\"\\nClassification Report for Fold:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=labels))\n",
        "\n",
        "    # Calculate accuracy and F1 score using binary arrays\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "    # Store scores for the current fold\n",
        "    accuracies.append(accuracy)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate mean probabilities\n",
        "mean_probabilities /= stratified_kfold.get_n_splits()  # Average the probabilities over folds\n",
        "\n",
        "# Find the highest mean probability\n",
        "highest_mean_label = labels[np.argmax(mean_probabilities)]\n",
        "highest_mean_probability = np.max(mean_probabilities)\n",
        "\n",
        "# Display overall results\n",
        "print(f'\\nMean Accuracy: {np.mean(accuracies)}')\n",
        "print(f'Mean F1 Score: {np.mean(f1_scores)}')\n",
        "print(\"\\nMean Probabilities for each class:\")\n",
        "for label, mean_prob in zip(labels, mean_probabilities):\n",
        "    print(f\"{label}: {mean_prob:.4f}\")\n",
        "\n",
        "print(f\"\\nHighest Mean Probability Label: {highest_mean_label} with probability: {highest_mean_probability:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5-k9A1gckby",
        "outputId": "1bc74b4c-4808-4918-c738-9525420168ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0350\n",
            "Food Quality: 0.2690\n",
            "Value for Money: 0.0490\n",
            "Comfort: 0.0548\n",
            "Staff Behavior: 0.5828\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.5828\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  8   5]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[146   4]\n",
            " [ 36  14]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[182   0]\n",
            " [ 14   4]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[175   0]\n",
            " [ 22   3]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[100   6]\n",
            " [  3  91]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      0.38      0.56        13\n",
            "   Food Quality       0.78      0.28      0.41        50\n",
            "Value for Money       1.00      0.22      0.36        18\n",
            "        Comfort       1.00      0.12      0.21        25\n",
            " Staff Behavior       0.94      0.97      0.95        94\n",
            "\n",
            "      micro avg       0.92      0.58      0.72       200\n",
            "      macro avg       0.94      0.39      0.50       200\n",
            "   weighted avg       0.92      0.58      0.65       200\n",
            "    samples avg       0.58      0.58      0.58       200\n",
            "\n",
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0334\n",
            "Food Quality: 0.2398\n",
            "Value for Money: 0.0529\n",
            "Comfort: 0.0561\n",
            "Staff Behavior: 0.6062\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.6062\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  8   5]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[147   3]\n",
            " [ 32  18]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[182   0]\n",
            " [ 12   6]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[174   1]\n",
            " [ 22   3]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[99  7]\n",
            " [ 6 88]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      0.38      0.56        13\n",
            "   Food Quality       0.86      0.36      0.51        50\n",
            "Value for Money       1.00      0.33      0.50        18\n",
            "        Comfort       0.75      0.12      0.21        25\n",
            " Staff Behavior       0.93      0.94      0.93        94\n",
            "\n",
            "      micro avg       0.92      0.60      0.73       200\n",
            "      macro avg       0.91      0.43      0.54       200\n",
            "   weighted avg       0.90      0.60      0.67       200\n",
            "    samples avg       0.59      0.60      0.60       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0359\n",
            "Food Quality: 0.2280\n",
            "Value for Money: 0.0528\n",
            "Comfort: 0.0603\n",
            "Staff Behavior: 0.5989\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.5989\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  6   7]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[150   0]\n",
            " [ 32  18]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[182   0]\n",
            " [ 13   5]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[175   0]\n",
            " [ 23   2]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[101   5]\n",
            " [  5  89]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      0.54      0.70        13\n",
            "   Food Quality       1.00      0.36      0.53        50\n",
            "Value for Money       1.00      0.28      0.43        18\n",
            "        Comfort       1.00      0.08      0.15        25\n",
            " Staff Behavior       0.95      0.95      0.95        94\n",
            "\n",
            "      micro avg       0.96      0.60      0.74       200\n",
            "      macro avg       0.99      0.44      0.55       200\n",
            "   weighted avg       0.97      0.60      0.68       200\n",
            "    samples avg       0.60      0.60      0.60       200\n",
            "\n",
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0342\n",
            "Food Quality: 0.2289\n",
            "Value for Money: 0.0515\n",
            "Comfort: 0.0574\n",
            "Staff Behavior: 0.6164\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.6164\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [ 10   3]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[149   1]\n",
            " [ 34  16]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[182   0]\n",
            " [ 14   4]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[175   0]\n",
            " [ 21   4]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[99  7]\n",
            " [10 84]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      0.23      0.38        13\n",
            "   Food Quality       0.94      0.32      0.48        50\n",
            "Value for Money       1.00      0.22      0.36        18\n",
            "        Comfort       1.00      0.16      0.28        25\n",
            " Staff Behavior       0.92      0.89      0.91        94\n",
            "\n",
            "      micro avg       0.93      0.56      0.70       200\n",
            "      macro avg       0.97      0.37      0.48       200\n",
            "   weighted avg       0.95      0.56      0.64       200\n",
            "    samples avg       0.56      0.56      0.56       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0348\n",
            "Food Quality: 0.2392\n",
            "Value for Money: 0.0442\n",
            "Comfort: 0.0588\n",
            "Staff Behavior: 0.6330\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 0.6330\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  8   4]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[148   1]\n",
            " [ 38  12]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[180   0]\n",
            " [ 16   3]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[174   0]\n",
            " [ 22   3]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[98  8]\n",
            " [ 8 85]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      0.33      0.50        12\n",
            "   Food Quality       0.92      0.24      0.38        50\n",
            "Value for Money       1.00      0.16      0.27        19\n",
            "        Comfort       1.00      0.12      0.21        25\n",
            " Staff Behavior       0.91      0.91      0.91        93\n",
            "\n",
            "      micro avg       0.92      0.54      0.68       199\n",
            "      macro avg       0.97      0.35      0.46       199\n",
            "   weighted avg       0.94      0.54      0.61       199\n",
            "    samples avg       0.54      0.54      0.54       199\n",
            "\n",
            "\n",
            "Mean Accuracy: 0.5715326633165829\n",
            "Mean F1 Score: 0.7116585983150111\n",
            "\n",
            "Mean Probabilities for each class:\n",
            "Location: 0.0347\n",
            "Food Quality: 0.2410\n",
            "Value for Money: 0.0501\n",
            "Comfort: 0.0575\n",
            "Staff Behavior: 0.6075\n",
            "\n",
            "Highest Mean Probability Label: Staff Behavior with probability: 0.6075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {
        "id": "zWVa_wTidZFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, f1_score, multilabel_confusion_matrix, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Preprocess the text\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "        return ' '.join(tokens)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Sample dataset II.csv')\n",
        "\n",
        "# Preprocess the text data\n",
        "df['preprocessed_text'] = df['reviews.text'].apply(preprocess_text)\n",
        "\n",
        "# Define label mapping\n",
        "labels = [\"Location\", \"Food Quality\", \"Value for Money\", \"Comfort\", \"Staff Behavior\"]\n",
        "\n",
        "# Create an instance of MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "# Apply K-means clustering to generate labels (dummy labels for demonstration)\n",
        "num_clusters = len(labels)  # Assuming we have 6 labels as defined above\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['preprocessed_text'])\n",
        "\n",
        "# Fit KMeans model\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "df['cluster_label'] = kmeans.labels_\n",
        "\n",
        "# Create a binary indicator for each cluster (multi-label format)\n",
        "y = pd.get_dummies(df['cluster_label']).values\n",
        "\n",
        "# Use StratifiedKFold to ensure stratified sampling\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Store accuracies, F1 scores, and probabilities for each fold\n",
        "accuracies = []\n",
        "f1_scores = []\n",
        "mean_probabilities = np.zeros(num_clusters)  # To store mean probabilities for each class\n",
        "\n",
        "for train_index, test_index in stratified_kfold.split(X, np.argmax(y, axis=1)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Create the Decision Tree model\n",
        "    base_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "    # Wrap the Decision Tree model with OneVsRestClassifier to handle multi-label classification\n",
        "    model = OneVsRestClassifier(base_model)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # New record to predict\n",
        "    new_record = [\"Great place with unique room structure with wooden top. It helped spending our own time without any disturbance. We can see Beautiful Sun rise from the room by opening the curtain.\"]\n",
        "    new_record_preprocessed = [preprocess_text(text) for text in new_record]\n",
        "    new_record_tfidf = vectorizer.transform(new_record_preprocessed)\n",
        "\n",
        "    # Predict the label for the new record\n",
        "    predicted_labels_numeric = model.predict(new_record_tfidf)\n",
        "\n",
        "    # Get the probabilities for each label category\n",
        "    probabilities = model.predict_proba(new_record_tfidf)\n",
        "\n",
        "    # Update mean probabilities\n",
        "    mean_probabilities += probabilities[0]  # Sum up probabilities for averaging later\n",
        "\n",
        "    # Display the predicted labels and probabilities\n",
        "    probability_dict = {labels[i]: probabilities[0][i] for i in range(num_clusters)}\n",
        "\n",
        "    # Find the label with the highest probability\n",
        "    highest_label = max(probability_dict, key=probability_dict.get)\n",
        "    highest_probability = probability_dict[highest_label]\n",
        "\n",
        "    # Display results for the current fold\n",
        "    print(f\"Predicted Labels: {predicted_labels_numeric}\")\n",
        "    print(\"Probabilities for each class:\")\n",
        "    for label, prob in probability_dict.items():\n",
        "        print(f\"{label}: {prob:.4f}\")  # Format to 4 decimal places\n",
        "\n",
        "    print(f\"\\nHighest Probability Label: {highest_label} with probability: {highest_probability:.4f}\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate the confusion matrix for each label\n",
        "    conf_matrix = multilabel_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Display confusion matrices for each label\n",
        "    for i, label in enumerate(labels):\n",
        "        print(f\"\\nConfusion Matrix for {label}:\")\n",
        "        print(conf_matrix[i])\n",
        "\n",
        "    # Generate and print precision, recall, and F1 score for each label\n",
        "    print(f\"\\nClassification Report for Fold:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=labels))\n",
        "\n",
        "    # Calculate accuracy and F1 score using binary arrays\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "    # Store scores for the current fold\n",
        "    accuracies.append(accuracy)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate mean probabilities\n",
        "mean_probabilities /= stratified_kfold.get_n_splits()  # Average the probabilities over folds\n",
        "\n",
        "# Find the highest mean probability\n",
        "highest_mean_label = labels[np.argmax(mean_probabilities)]\n",
        "highest_mean_probability = np.max(mean_probabilities)\n",
        "\n",
        "# Display overall results\n",
        "print(f'\\nMean Accuracy: {np.mean(accuracies)}')\n",
        "print(f'Mean F1 Score: {np.mean(f1_scores)}')\n",
        "print(\"\\nMean Probabilities for each class:\")\n",
        "for label, mean_prob in zip(labels, mean_probabilities):\n",
        "    print(f\"{label}: {mean_prob:.4f}\")\n",
        "\n",
        "print(f\"\\nHighest Mean Probability Label: {highest_mean_label} with probability: {highest_mean_probability:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEIWLyPWdk-x",
        "outputId": "bef73cd3-cab6-4ae4-9d39-1a3e1e6c40b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0000\n",
            "Food Quality: 0.0000\n",
            "Value for Money: 0.0000\n",
            "Comfort: 0.0000\n",
            "Staff Behavior: 1.0000\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 1.0000\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  0  13]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[139  11]\n",
            " [ 17  33]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[178   4]\n",
            " [  5  13]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[168   7]\n",
            " [ 10  15]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[86 20]\n",
            " [18 76]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      1.00      1.00        13\n",
            "   Food Quality       0.75      0.66      0.70        50\n",
            "Value for Money       0.76      0.72      0.74        18\n",
            "        Comfort       0.68      0.60      0.64        25\n",
            " Staff Behavior       0.79      0.81      0.80        94\n",
            "\n",
            "      micro avg       0.78      0.75      0.77       200\n",
            "      macro avg       0.80      0.76      0.78       200\n",
            "   weighted avg       0.78      0.75      0.76       200\n",
            "    samples avg       0.71      0.75      0.73       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0000\n",
            "Food Quality: 0.0000\n",
            "Value for Money: 0.0000\n",
            "Comfort: 0.0000\n",
            "Staff Behavior: 1.0000\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 1.0000\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  2  11]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[138  12]\n",
            " [ 13  37]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[170  12]\n",
            " [  4  14]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[170   5]\n",
            " [  5  20]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[95 11]\n",
            " [23 71]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      0.85      0.92        13\n",
            "   Food Quality       0.76      0.74      0.75        50\n",
            "Value for Money       0.54      0.78      0.64        18\n",
            "        Comfort       0.80      0.80      0.80        25\n",
            " Staff Behavior       0.87      0.76      0.81        94\n",
            "\n",
            "      micro avg       0.79      0.77      0.78       200\n",
            "      macro avg       0.79      0.78      0.78       200\n",
            "   weighted avg       0.81      0.77      0.78       200\n",
            "    samples avg       0.74      0.77      0.75       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0000\n",
            "Food Quality: 0.0000\n",
            "Value for Money: 0.0000\n",
            "Comfort: 0.0000\n",
            "Staff Behavior: 1.0000\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 1.0000\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  0  13]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[134  16]\n",
            " [ 17  33]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[178   4]\n",
            " [  6  12]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[167   8]\n",
            " [  7  18]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[94 12]\n",
            " [16 78]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      1.00      1.00        13\n",
            "   Food Quality       0.67      0.66      0.67        50\n",
            "Value for Money       0.75      0.67      0.71        18\n",
            "        Comfort       0.69      0.72      0.71        25\n",
            " Staff Behavior       0.87      0.83      0.85        94\n",
            "\n",
            "      micro avg       0.79      0.77      0.78       200\n",
            "      macro avg       0.80      0.78      0.79       200\n",
            "   weighted avg       0.79      0.77      0.78       200\n",
            "    samples avg       0.72      0.77      0.74       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0000\n",
            "Food Quality: 0.0000\n",
            "Value for Money: 0.0000\n",
            "Comfort: 0.0000\n",
            "Staff Behavior: 1.0000\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 1.0000\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  0  13]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[140  10]\n",
            " [ 17  33]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[179   3]\n",
            " [  4  14]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[167   8]\n",
            " [  5  20]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[92 14]\n",
            " [13 81]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      1.00      1.00        13\n",
            "   Food Quality       0.77      0.66      0.71        50\n",
            "Value for Money       0.82      0.78      0.80        18\n",
            "        Comfort       0.71      0.80      0.75        25\n",
            " Staff Behavior       0.85      0.86      0.86        94\n",
            "\n",
            "      micro avg       0.82      0.81      0.81       200\n",
            "      macro avg       0.83      0.82      0.82       200\n",
            "   weighted avg       0.82      0.81      0.81       200\n",
            "    samples avg       0.77      0.81      0.78       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [[0 0 0 0 1]]\n",
            "Probabilities for each class:\n",
            "Location: 0.0000\n",
            "Food Quality: 0.0000\n",
            "Value for Money: 0.0000\n",
            "Comfort: 0.0000\n",
            "Staff Behavior: 1.0000\n",
            "\n",
            "Highest Probability Label: Staff Behavior with probability: 1.0000\n",
            "\n",
            "Confusion Matrix for Location:\n",
            "[[187   0]\n",
            " [  1  11]]\n",
            "\n",
            "Confusion Matrix for Food Quality:\n",
            "[[134  15]\n",
            " [ 12  38]]\n",
            "\n",
            "Confusion Matrix for Value for Money:\n",
            "[[174   6]\n",
            " [  8  11]]\n",
            "\n",
            "Confusion Matrix for Comfort:\n",
            "[[163  11]\n",
            " [  5  20]]\n",
            "\n",
            "Confusion Matrix for Staff Behavior:\n",
            "[[93 13]\n",
            " [11 82]]\n",
            "\n",
            "Classification Report for Fold:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      0.92      0.96        12\n",
            "   Food Quality       0.72      0.76      0.74        50\n",
            "Value for Money       0.65      0.58      0.61        19\n",
            "        Comfort       0.65      0.80      0.71        25\n",
            " Staff Behavior       0.86      0.88      0.87        93\n",
            "\n",
            "      micro avg       0.78      0.81      0.80       199\n",
            "      macro avg       0.77      0.79      0.78       199\n",
            "   weighted avg       0.79      0.81      0.80       199\n",
            "    samples avg       0.76      0.81      0.78       199\n",
            "\n",
            "\n",
            "Mean Accuracy: 0.705713567839196\n",
            "Mean F1 Score: 0.787363766950777\n",
            "\n",
            "Mean Probabilities for each class:\n",
            "Location: 0.0000\n",
            "Food Quality: 0.0000\n",
            "Value for Money: 0.0000\n",
            "Comfort: 0.0000\n",
            "Staff Behavior: 1.0000\n",
            "\n",
            "Highest Mean Probability Label: Staff Behavior with probability: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Neural Network"
      ],
      "metadata": {
        "id": "uhgXMCI1eDPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.cluster import KMeans\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Preprocess the text\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "        return ' '.join(tokens)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('Sample dataset II.csv')\n",
        "\n",
        "# Preprocess the text data\n",
        "df['preprocessed_text'] = df['reviews.text'].apply(preprocess_text)\n",
        "\n",
        "# Define label mapping\n",
        "labels = [\"Location\", \"Food Quality\", \"Value for Money\", \"Comfort\", \"Staff Behavior\"]\n",
        "\n",
        "# Create an instance of MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "# Apply K-means clustering to generate labels (dummy labels for demonstration)\n",
        "num_clusters = len(labels)\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['preprocessed_text'])\n",
        "\n",
        "# Fit KMeans model\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "df['cluster_label'] = kmeans.labels_\n",
        "\n",
        "# Create a binary indicator for each cluster (multi-label format)\n",
        "y = pd.get_dummies(df['cluster_label']).values\n",
        "\n",
        "# Define a function to create a DNN model\n",
        "def create_dnn_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='sigmoid')  # Sigmoid for multi-label output\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Use StratifiedKFold to ensure stratified sampling\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Store accuracies and reports for each fold\n",
        "accuracies = []\n",
        "classification_reports = []\n",
        "\n",
        "for train_index, test_index in stratified_kfold.split(X, np.argmax(y, axis=1)):\n",
        "    X_train, X_test = X[train_index].toarray(), X[test_index].toarray()\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Create the DNN model\n",
        "    model = create_dnn_model(X_train.shape[1], num_clusters)\n",
        "\n",
        "    # Set early stopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=20,\n",
        "                        batch_size=32,\n",
        "                        validation_split=0.2,\n",
        "                        callbacks=[early_stopping],\n",
        "                        verbose=1)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to binary values\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    # Generate and store classification report\n",
        "    report = classification_report(y_test, y_pred, target_names=labels, output_dict=True)\n",
        "    classification_reports.append(report)\n",
        "\n",
        "    # Display results for the current fold\n",
        "    print(f\"\\nFold Accuracy: {accuracy}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=labels))\n",
        "\n",
        "# Display overall results\n",
        "print(f'\\nMean Accuracy across folds: {np.mean(accuracies)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4U6WH0ceG3p",
        "outputId": "3eadcc5c-0781-4958-9289-c4c0a362c833"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.3114 - loss: 0.6826 - val_accuracy: 0.5188 - val_loss: 0.6281\n",
            "Epoch 2/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4732 - loss: 0.5935 - val_accuracy: 0.5188 - val_loss: 0.4769\n",
            "Epoch 3/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4724 - loss: 0.4545 - val_accuracy: 0.5188 - val_loss: 0.4088\n",
            "Epoch 4/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5079 - loss: 0.4020 - val_accuracy: 0.5188 - val_loss: 0.3877\n",
            "Epoch 5/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5657 - loss: 0.3606 - val_accuracy: 0.5625 - val_loss: 0.3613\n",
            "Epoch 6/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7054 - loss: 0.3090 - val_accuracy: 0.6438 - val_loss: 0.3273\n",
            "Epoch 7/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7964 - loss: 0.2315 - val_accuracy: 0.6750 - val_loss: 0.2906\n",
            "Epoch 8/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8484 - loss: 0.1879 - val_accuracy: 0.6938 - val_loss: 0.2607\n",
            "Epoch 9/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9139 - loss: 0.1286 - val_accuracy: 0.7375 - val_loss: 0.2389\n",
            "Epoch 10/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9460 - loss: 0.1066 - val_accuracy: 0.7625 - val_loss: 0.2211\n",
            "Epoch 11/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9838 - loss: 0.0745 - val_accuracy: 0.7812 - val_loss: 0.2092\n",
            "Epoch 12/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9829 - loss: 0.0624 - val_accuracy: 0.7812 - val_loss: 0.2005\n",
            "Epoch 13/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9959 - loss: 0.0477 - val_accuracy: 0.8000 - val_loss: 0.1984\n",
            "Epoch 14/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0345 - val_accuracy: 0.8000 - val_loss: 0.1986\n",
            "Epoch 15/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0272 - val_accuracy: 0.8000 - val_loss: 0.1950\n",
            "Epoch 16/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 0.8125 - val_loss: 0.1903\n",
            "Epoch 17/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9980 - loss: 0.0185 - val_accuracy: 0.8000 - val_loss: 0.1870\n",
            "Epoch 18/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9989 - loss: 0.0202 - val_accuracy: 0.8062 - val_loss: 0.1879\n",
            "Epoch 19/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.8125 - val_loss: 0.1903\n",
            "Epoch 20/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.7875 - val_loss: 0.1943\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\n",
            "Fold Accuracy: 0.74\n",
            "\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      1.00      1.00        13\n",
            "   Food Quality       0.91      0.60      0.72        50\n",
            "Value for Money       1.00      0.72      0.84        18\n",
            "        Comfort       1.00      0.52      0.68        25\n",
            " Staff Behavior       0.86      0.86      0.86        94\n",
            "\n",
            "      micro avg       0.90      0.75      0.82       200\n",
            "      macro avg       0.95      0.74      0.82       200\n",
            "   weighted avg       0.91      0.75      0.81       200\n",
            "    samples avg       0.74      0.75      0.75       200\n",
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.3087 - loss: 0.6857 - val_accuracy: 0.5312 - val_loss: 0.6393\n",
            "Epoch 2/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4679 - loss: 0.6109 - val_accuracy: 0.5312 - val_loss: 0.5096\n",
            "Epoch 3/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4607 - loss: 0.4889 - val_accuracy: 0.5312 - val_loss: 0.4202\n",
            "Epoch 4/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4671 - loss: 0.4176 - val_accuracy: 0.5312 - val_loss: 0.3817\n",
            "Epoch 5/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5424 - loss: 0.3768 - val_accuracy: 0.5875 - val_loss: 0.3524\n",
            "Epoch 6/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6956 - loss: 0.3083 - val_accuracy: 0.6625 - val_loss: 0.3180\n",
            "Epoch 7/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7755 - loss: 0.2444 - val_accuracy: 0.6687 - val_loss: 0.2869\n",
            "Epoch 8/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8214 - loss: 0.1964 - val_accuracy: 0.7312 - val_loss: 0.2652\n",
            "Epoch 9/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8486 - loss: 0.1690 - val_accuracy: 0.7063 - val_loss: 0.2522\n",
            "Epoch 10/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8869 - loss: 0.1426 - val_accuracy: 0.7312 - val_loss: 0.2354\n",
            "Epoch 11/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9183 - loss: 0.1203 - val_accuracy: 0.7563 - val_loss: 0.2232\n",
            "Epoch 12/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9610 - loss: 0.0866 - val_accuracy: 0.7500 - val_loss: 0.2129\n",
            "Epoch 13/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9865 - loss: 0.0631 - val_accuracy: 0.7688 - val_loss: 0.2080\n",
            "Epoch 14/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9833 - loss: 0.0585 - val_accuracy: 0.8062 - val_loss: 0.1980\n",
            "Epoch 15/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9915 - loss: 0.0426 - val_accuracy: 0.8062 - val_loss: 0.1931\n",
            "Epoch 16/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0282 - val_accuracy: 0.8125 - val_loss: 0.1910\n",
            "Epoch 17/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0273 - val_accuracy: 0.7875 - val_loss: 0.1941\n",
            "Epoch 18/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9997 - loss: 0.0184 - val_accuracy: 0.8188 - val_loss: 0.1915\n",
            "Epoch 19/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9935 - loss: 0.0208 - val_accuracy: 0.8313 - val_loss: 0.1878\n",
            "Epoch 20/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.8188 - val_loss: 0.1925\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\n",
            "Fold Accuracy: 0.78\n",
            "\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      1.00      1.00        13\n",
            "   Food Quality       0.87      0.66      0.75        50\n",
            "Value for Money       1.00      0.50      0.67        18\n",
            "        Comfort       0.93      0.52      0.67        25\n",
            " Staff Behavior       0.87      0.95      0.91        94\n",
            "\n",
            "      micro avg       0.89      0.79      0.84       200\n",
            "      macro avg       0.93      0.73      0.80       200\n",
            "   weighted avg       0.90      0.79      0.82       200\n",
            "    samples avg       0.78      0.79      0.78       200\n",
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.2927 - loss: 0.6809 - val_accuracy: 0.5500 - val_loss: 0.6250\n",
            "Epoch 2/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4748 - loss: 0.5870 - val_accuracy: 0.4812 - val_loss: 0.4725\n",
            "Epoch 3/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4922 - loss: 0.4497 - val_accuracy: 0.4812 - val_loss: 0.4108\n",
            "Epoch 4/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4994 - loss: 0.4016 - val_accuracy: 0.5188 - val_loss: 0.3837\n",
            "Epoch 5/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5965 - loss: 0.3466 - val_accuracy: 0.5875 - val_loss: 0.3504\n",
            "Epoch 6/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7265 - loss: 0.2771 - val_accuracy: 0.6313 - val_loss: 0.3184\n",
            "Epoch 7/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7644 - loss: 0.2291 - val_accuracy: 0.6562 - val_loss: 0.2956\n",
            "Epoch 8/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8298 - loss: 0.1795 - val_accuracy: 0.6812 - val_loss: 0.2758\n",
            "Epoch 9/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8890 - loss: 0.1409 - val_accuracy: 0.6500 - val_loss: 0.2660\n",
            "Epoch 10/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9321 - loss: 0.1207 - val_accuracy: 0.7063 - val_loss: 0.2473\n",
            "Epoch 11/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9608 - loss: 0.0900 - val_accuracy: 0.7063 - val_loss: 0.2475\n",
            "Epoch 12/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9778 - loss: 0.0741 - val_accuracy: 0.7312 - val_loss: 0.2333\n",
            "Epoch 13/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0574 - val_accuracy: 0.7437 - val_loss: 0.2304\n",
            "Epoch 14/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9971 - loss: 0.0414 - val_accuracy: 0.7563 - val_loss: 0.2259\n",
            "Epoch 15/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9939 - loss: 0.0368 - val_accuracy: 0.7625 - val_loss: 0.2228\n",
            "Epoch 16/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0250 - val_accuracy: 0.7688 - val_loss: 0.2243\n",
            "Epoch 17/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9977 - loss: 0.0248 - val_accuracy: 0.7750 - val_loss: 0.2209\n",
            "Epoch 18/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0224 - val_accuracy: 0.7812 - val_loss: 0.2204\n",
            "Epoch 19/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9988 - loss: 0.0161 - val_accuracy: 0.7875 - val_loss: 0.2199\n",
            "Epoch 20/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.7937 - val_loss: 0.2235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a2f4b96d630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold Accuracy: 0.77\n",
            "\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      1.00      1.00        13\n",
            "   Food Quality       0.91      0.62      0.74        50\n",
            "Value for Money       0.90      0.50      0.64        18\n",
            "        Comfort       0.93      0.52      0.67        25\n",
            " Staff Behavior       0.85      0.94      0.89        94\n",
            "\n",
            "      micro avg       0.89      0.77      0.82       200\n",
            "      macro avg       0.92      0.72      0.79       200\n",
            "   weighted avg       0.89      0.77      0.81       200\n",
            "    samples avg       0.77      0.77      0.77       200\n",
            "\n",
            "Epoch 1/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.3694 - loss: 0.6814 - val_accuracy: 0.5188 - val_loss: 0.6251\n",
            "Epoch 2/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4387 - loss: 0.5901 - val_accuracy: 0.5188 - val_loss: 0.4843\n",
            "Epoch 3/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4462 - loss: 0.4638 - val_accuracy: 0.5188 - val_loss: 0.4162\n",
            "Epoch 4/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4854 - loss: 0.4048 - val_accuracy: 0.5312 - val_loss: 0.3860\n",
            "Epoch 5/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5427 - loss: 0.3677 - val_accuracy: 0.5813 - val_loss: 0.3592\n",
            "Epoch 6/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6948 - loss: 0.2869 - val_accuracy: 0.6562 - val_loss: 0.3295\n",
            "Epoch 7/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7445 - loss: 0.2526 - val_accuracy: 0.6625 - val_loss: 0.3021\n",
            "Epoch 8/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8078 - loss: 0.2015 - val_accuracy: 0.6812 - val_loss: 0.2822\n",
            "Epoch 9/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8757 - loss: 0.1453 - val_accuracy: 0.7063 - val_loss: 0.2671\n",
            "Epoch 10/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9079 - loss: 0.1225 - val_accuracy: 0.7250 - val_loss: 0.2532\n",
            "Epoch 11/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9314 - loss: 0.0980 - val_accuracy: 0.7437 - val_loss: 0.2442\n",
            "Epoch 12/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9731 - loss: 0.0768 - val_accuracy: 0.7437 - val_loss: 0.2379\n",
            "Epoch 13/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9788 - loss: 0.0587 - val_accuracy: 0.7625 - val_loss: 0.2365\n",
            "Epoch 14/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9929 - loss: 0.0494 - val_accuracy: 0.7563 - val_loss: 0.2338\n",
            "Epoch 15/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9879 - loss: 0.0402 - val_accuracy: 0.7812 - val_loss: 0.2278\n",
            "Epoch 16/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9973 - loss: 0.0269 - val_accuracy: 0.7750 - val_loss: 0.2277\n",
            "Epoch 17/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9898 - loss: 0.0230 - val_accuracy: 0.7688 - val_loss: 0.2322\n",
            "Epoch 18/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9966 - loss: 0.0192 - val_accuracy: 0.7625 - val_loss: 0.2306\n",
            "Epoch 19/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9956 - loss: 0.0184 - val_accuracy: 0.7375 - val_loss: 0.2291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a2f4b883ac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold Accuracy: 0.715\n",
            "\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      1.00      1.00        13\n",
            "   Food Quality       0.83      0.70      0.76        50\n",
            "Value for Money       1.00      0.56      0.71        18\n",
            "        Comfort       1.00      0.44      0.61        25\n",
            " Staff Behavior       0.81      0.79      0.80        94\n",
            "\n",
            "      micro avg       0.86      0.71      0.78       200\n",
            "      macro avg       0.93      0.70      0.78       200\n",
            "   weighted avg       0.87      0.71      0.77       200\n",
            "    samples avg       0.71      0.71      0.71       200\n",
            "\n",
            "Epoch 1/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.4049 - loss: 0.6745 - val_accuracy: 0.5250 - val_loss: 0.6006\n",
            "Epoch 2/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4694 - loss: 0.5619 - val_accuracy: 0.5250 - val_loss: 0.4527\n",
            "Epoch 3/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4536 - loss: 0.4453 - val_accuracy: 0.5250 - val_loss: 0.4014\n",
            "Epoch 4/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4954 - loss: 0.3891 - val_accuracy: 0.5562 - val_loss: 0.3739\n",
            "Epoch 5/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6159 - loss: 0.3395 - val_accuracy: 0.6187 - val_loss: 0.3396\n",
            "Epoch 6/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7036 - loss: 0.2850 - val_accuracy: 0.6812 - val_loss: 0.3017\n",
            "Epoch 7/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8281 - loss: 0.2189 - val_accuracy: 0.7125 - val_loss: 0.2714\n",
            "Epoch 8/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8958 - loss: 0.1730 - val_accuracy: 0.7375 - val_loss: 0.2484\n",
            "Epoch 9/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9119 - loss: 0.1316 - val_accuracy: 0.7875 - val_loss: 0.2293\n",
            "Epoch 10/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9738 - loss: 0.1075 - val_accuracy: 0.8062 - val_loss: 0.2179\n",
            "Epoch 11/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9880 - loss: 0.0773 - val_accuracy: 0.8062 - val_loss: 0.2106\n",
            "Epoch 12/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9876 - loss: 0.0621 - val_accuracy: 0.8125 - val_loss: 0.2073\n",
            "Epoch 13/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9952 - loss: 0.0440 - val_accuracy: 0.8313 - val_loss: 0.1961\n",
            "Epoch 14/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.0380 - val_accuracy: 0.8375 - val_loss: 0.1932\n",
            "Epoch 15/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9911 - loss: 0.0349 - val_accuracy: 0.8250 - val_loss: 0.1955\n",
            "Epoch 16/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0254 - val_accuracy: 0.8313 - val_loss: 0.1977\n",
            "Epoch 17/20\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 0.8375 - val_loss: 0.2001\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\n",
            "Fold Accuracy: 0.7236180904522613\n",
            "\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       Location       1.00      0.92      0.96        12\n",
            "   Food Quality       0.88      0.70      0.78        50\n",
            "Value for Money       1.00      0.42      0.59        19\n",
            "        Comfort       1.00      0.40      0.57        25\n",
            " Staff Behavior       0.91      0.86      0.88        93\n",
            "\n",
            "      micro avg       0.92      0.72      0.81       199\n",
            "      macro avg       0.96      0.66      0.76       199\n",
            "   weighted avg       0.93      0.72      0.79       199\n",
            "    samples avg       0.72      0.72      0.72       199\n",
            "\n",
            "\n",
            "Mean Accuracy across folds: 0.7457236180904523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}